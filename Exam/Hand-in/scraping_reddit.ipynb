{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from praw.models import MoreComments\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import nltk.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit API authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='BxrF2g9d3egQ4g', \\\n",
    "                     client_secret='T-pkCmWCBxLjVlNZk88OjvcH7sk', \\\n",
    "                     user_agent='SDS2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download comments for movies on reddit with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting Reddit comments for movie title\n",
    "def get_reddit_comments(movie_title):\n",
    "    # Get 'movies subreddit'\n",
    "    subreddit = reddit.subreddit('movies')\n",
    "    \n",
    "    # Prepare lists for information\n",
    "    comments = []\n",
    "    subid = []\n",
    "    treeid = []\n",
    "    date = []\n",
    "    \n",
    "    # Search Reddit\n",
    "    searchresults = subreddit.search(movie_title, sort = 'relevance')\n",
    "    \n",
    "    # Store all commens\n",
    "    i = 0\n",
    "    for subidx, submission in enumerate(searchresults):\n",
    "        \n",
    "        # Stop after 5 submissions\n",
    "        if i == 5:\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "        # Try to get more comments\n",
    "        try:\n",
    "            comment_tree = submission.comments.list()\n",
    "            for treeidx, top_lvl_comment in enumerate(comment_tree):\n",
    "                \n",
    "                if isinstance(top_lvl_comment, MoreComments):\n",
    "                    continue\n",
    "                \n",
    "                # Append information to dataframe\n",
    "                subid.append(subidx)\n",
    "                comments.append(top_lvl_comment.body)\n",
    "                treeid.append(treeidx)\n",
    "                date.append(top_lvl_comment.created_utc)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Store information in dataframe\n",
    "    df = pd.DataFrame({'submission': subid, 'comment_tree': treeid, 'comment': comments, 'date': date, 'movie': movie_title})\n",
    "    df['date'] = pd.to_datetime(df['date'], unit = 's')\n",
    "    df = df.set_index(['date'])\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    # Next iteration\n",
    "    i += 1\n",
    "    \n",
    "    # Return dataframe of comments\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguistic analysis of commments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting sentiment scores of comments\n",
    "def sentiment(movie_df):\n",
    "    vader = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
    "    vader_df = pd.DataFrame(list(movie_df['comment'].apply(vader.polarity_scores)))\n",
    "    vader_mean = vader_df['compound'].mean()\n",
    "    return vader_mean, len(vader_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing movies and release dates from movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe with movies\n",
    "df = pd.read_pickle('full.pkl')\n",
    "\n",
    "# Select on years from 2010 and forward\n",
    "df = df[df['year'] >= 2010]\n",
    "\n",
    "# Convert dataframe into lists\n",
    "movie_list = df['title'].tolist()\n",
    "date_list = df['releaseDate'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sentiment scores for all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write list of positive words\n",
    "words = ['Oscar', 'Oscars', 'Academy Award', 'Academy', 'Best Picture', 'Best Director', 'Best Actor', 'Best Actress', \\\n",
    "        'Best Supporting Actor', 'Best Supporting Actress', 'Best Original Screenplay', 'Best Adapted Screenplay', \\\n",
    "        'Best Animated Feature Film', 'Best Foreign Langauge Film', 'Golden Globe']\n",
    "\n",
    "# Prepare dataframe for filling\n",
    "sentiments_before = []\n",
    "sentiments_after = []\n",
    "num_comments_before = []\n",
    "num_comments_after = []\n",
    "positive_words_before = []\n",
    "positive_words_after = []\n",
    "\n",
    "# Loop through all movies and get sentiment scores\n",
    "i = 1\n",
    "for movie, date in zip(movie_list, date_list):\n",
    "    # Try to get the comments for the movie\n",
    "    try:\n",
    "        comments = get_reddit_comments(movie, testing = True)\n",
    "    except:\n",
    "        sentiments_before.append(None)\n",
    "        sentiments_after.append(None)\n",
    "        num_comments_before.append(None)\n",
    "        num_comments_after.append(None)\n",
    "        continue\n",
    "    \n",
    "    # Try to get comments before release dte\n",
    "    try:\n",
    "        comments_before = comments[:date - datetime.timedelta(days = 1)]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to get comments after release date\n",
    "    try:\n",
    "        comments_after = comments[date:date + datetime.timedelta(days = 60)]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Count positive words before release\n",
    "    positive_count_before = 0\n",
    "    try:\n",
    "        for comment in comments_before['comment']:\n",
    "            for word in words:\n",
    "                if word.lower() in comment.lower():\n",
    "                    positive_count_before += 1\n",
    "        positive_words_before.append(positive_count_before)\n",
    "    except:\n",
    "        positive_words_before.append(None)\n",
    "    \n",
    "    # Count positive words after release\n",
    "    positive_count_after = 0\n",
    "    try:\n",
    "        for comment in comments_after['comment']:\n",
    "            for word in words:\n",
    "                if word.lower() in comment.lower():\n",
    "                    positive_count_after += 1\n",
    "        positive_words_after.append(positive_count_after)\n",
    "    except:\n",
    "        positive_words_after.append(None)\n",
    "    \n",
    "    # Try to append comments dataframes\n",
    "    if i == 1:\n",
    "        try:\n",
    "            all_comments_before = comments_before\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            all_comments_after = comments_after\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            all_comments_before = all_comments_before.append(comments_before)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            all_comments_after = all_comments_after.append(comments_after)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Try to append sentiments before to list\n",
    "    try:\n",
    "        snt_before = sentiment(comments_before)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to append sentiments after to list\n",
    "    try:\n",
    "        snt_after = sentiment(comments_after)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to append sentiments before to list\n",
    "    try:\n",
    "        sentiments_before.append(snt_before[0])\n",
    "    except:\n",
    "        sentiments_before.append(None)\n",
    "    \n",
    "    # Try to append sentiments after to list\n",
    "    try:\n",
    "        sentiments_after.append(snt_after[0])\n",
    "    except:\n",
    "        sentiments_after.append(None)\n",
    "        \n",
    "    # Try to append comments before to list\n",
    "    try:\n",
    "        num_comments_before.append(snt_before[1])\n",
    "    except:\n",
    "        num_comments_before.append(None)\n",
    "    \n",
    "    # Try to append comments after to list\n",
    "    try:\n",
    "        num_comments_after.append(snt_after[1])\n",
    "    except:\n",
    "        num_comments_after.append(None)\n",
    "        \n",
    "    print(i)\n",
    "    i += 1\n",
    "\n",
    "# Store lists in dataframe\n",
    "df['sentimentBefore'] = sentiments_before\n",
    "df['sentimentAfter'] = sentiments_after\n",
    "df['numCommentsBefore'] = num_comments_before\n",
    "df['numCommentsAfter'] = num_comments_after\n",
    "df['positiveWordsBefore'] = positive_words_before\n",
    "df['positiveWordsAfter'] = positive_words_after\n",
    "\n",
    "# Save dataframes\n",
    "df.to_pickle('full_w_sentiment.pkl')\n",
    "all_comments_before.to_pickle('all_comments_before.pkl')\n",
    "all_comments_after.to_pickle('all_comments_after.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
