{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso, LinearRegression, ElasticNet\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, validation_curve, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_pickle('full_w_sentiment.pkl')\n",
    "\n",
    "# Function for getting possible values in dataframe columns\n",
    "def possible_values(df, colname):\n",
    "    out = set([])\n",
    "    for row in df[colname]:\n",
    "        for g in row:\n",
    "            out.add(g)\n",
    "    return out\n",
    "\n",
    "# Function for getting dummies for dataframe with columns of lists\n",
    "def dummies_from_nested_categories(df, colname):\n",
    "    possible_valuess = possible_values(df, colname)\n",
    "    \n",
    "    def clean(s):\n",
    "        return s.replace(' ', '').replace('&', '').lower()\n",
    "    \n",
    "    for pos in possible_valuess:\n",
    "        df['d_' + clean(pos)] = df[colname].apply(lambda x: pos in x).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Create dummies for mpaaRating\n",
    "dummies = pd.get_dummies(df['mpaaRating'])\n",
    "df = pd.concat([df, dummies], axis = 1)\n",
    "\n",
    "# Create dummies for genres\n",
    "dummies_from_nested_categories(df, 'genres')\n",
    "\n",
    "# Create dummies for studio\n",
    "dummies = pd.get_dummies(df['studio'])\n",
    "df = pd.concat([df, dummies], axis = 1)\n",
    "\n",
    "# Drop non-features\n",
    "data = df.drop(['actors', 'mpaaRating', 'synopsis', 'title', 'tomatoIcon', 'releaseDate', 'genres', 'directors', \\\n",
    "                'studio', 'tomatoCount', 'audienceCount', 'year', 'titleType', \\\n",
    "                'isAdult', 'numVotes', 'boRank', 'studioAcronym', 'totalTheaters', \\\n",
    "                'boOpening', 'openingTheaters', 'sentimentAfter', 'numCommentsAfter', 'positiveWordsAfter'], axis = 1)\n",
    "\n",
    "# Function for turning string into float\n",
    "def get_float(string):\n",
    "    try:\n",
    "        return float(string)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Turn columns into floats\n",
    "items = ['tomatoMeter', 'audienceScore', 'runtime', 'boWorldwide']\n",
    "for item in items:\n",
    "    data[item] = data[item].apply(get_float)\n",
    "\n",
    "# Drop not available observations\n",
    "data = data.dropna(subset = items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test\n",
    "train, test = train_test_split(data, test_size = 0.25)\n",
    "\n",
    "# Create target dataframes\n",
    "y_train = train[['tomatoMeter', 'audienceScore', 'averageRating', 'boWorldwide']]\n",
    "y_train['boWorldwide'] = np.log(y_train['boWorldwide'])\n",
    "y_test = test[['tomatoMeter', 'audienceScore', 'averageRating', 'boWorldwide']]\n",
    "y_test['boWorldwide'] = np.log(y_test['boWorldwide'])\n",
    "\n",
    "# Create feature dataframes\n",
    "X_train = train.drop(['tomatoMeter', 'audienceScore', 'averageRating', 'boWorldwide'], axis = 1)\n",
    "X_test = test.drop(['tomatoMeter', 'audienceScore', 'averageRating', 'boWorldwide'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list for storing linear regressions\n",
    "lregs = []\n",
    "\n",
    "# Fit linear regressions for different targets, outputting MSE and R-squared for each\n",
    "i = 1\n",
    "for target in y_train:\n",
    "    lreg = LinearRegression()\n",
    "    lreg.fit(X_train, y_train[target])\n",
    "\n",
    "    print(target + ':', mean_squared_error(y_test[target], lreg.predict(X_test)), r2_score(y_test[target], lreg.predict(X_test)))\n",
    "    lregs.append(lreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pipeline for Lasso\n",
    "pipe = make_pipeline(StandardScaler(), Lasso(random_state = 1))\n",
    "\n",
    "# Create list for storing Lassos\n",
    "gs_lassos = []\n",
    "\n",
    "# Fit Lassos for different targets, outputting MSE and R-squared for each\n",
    "for target in y_train:\n",
    "    gs_lasso = GridSearchCV(estimator = pipe, param_grid = {'lasso__alpha': np.logspace(-4, 4, 12)}, \\\n",
    "                      scoring = 'neg_mean_squared_error', n_jobs = -1, iid = False, cv = 10, verbose = 0)\n",
    "    gs_lasso.fit(X_train, y_train[target])\n",
    "\n",
    "    print(target + ':', mean_squared_error(y_test[target], gs_lasso.best_estimator_.predict(X_test)), r2_score(y_test[target], gs_lasso.best_estimator_.predict(X_test)))\n",
    "    gs_lassos.append(gs_lasso)\n",
    "    \n",
    "# Get coefficients regarding Reddit comments\n",
    "print(gs_lassos[0].best_estimator_.steps[1][1].coef_[3:6])\n",
    "print(gs_lassos[2].best_estimator_.steps[1][1].coef_[3:6])\n",
    "print(gs_lassos[3].best_estimator_.steps[1][1].coef_[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curves for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "# Creat figure\n",
    "fig, axes = plt.subplots(1, 3, figsize = (8, 2))\n",
    "\n",
    "# Create dataframe for Lasso with target average rating\n",
    "lasso_average_val = pd.DataFrame()\n",
    "lasso_average_val['Validation'] = -gs_lassos[2].cv_results_['mean_test_score']\n",
    "lasso_average_val['Train'] = -gs_lassos[2].cv_results_['mean_train_score']\n",
    "lasso_average_val['Lambda'] = np.logspace(-4, 4, 12)\n",
    "lasso_average_val = lasso_average_val.set_index('Lambda')\n",
    "lasso_average_val.plot(logx = True, logy = True, ax = axes[0], legend = False)\n",
    "\n",
    "# Create dataframe for Lasso with target Tomatometer\n",
    "lasso_tomato_val = pd.DataFrame()\n",
    "lasso_tomato_val['Validation'] = -gs_lassos[0].cv_results_['mean_test_score']\n",
    "lasso_tomato_val['Train'] = -gs_lassos[0].cv_results_['mean_train_score']\n",
    "lasso_tomato_val['Lambda'] = np.logspace(-4, 4, 12)\n",
    "lasso_tomato_val = lasso_tomato_val.set_index('Lambda')\n",
    "lasso_tomato_val.plot(logx = True, logy = True, ax = axes[1], legend = False)\n",
    "\n",
    "# Create dataframe for Lasso with target box office\n",
    "lasso_bo_val = pd.DataFrame()\n",
    "lasso_bo_val['Validation'] = -gs_lassos[3].cv_results_['mean_test_score']\n",
    "lasso_bo_val['Train'] = -gs_lassos[3].cv_results_['mean_train_score']\n",
    "lasso_bo_val['Lambda'] = np.logspace(-4, 4, 12)\n",
    "lasso_bo_val = lasso_bo_val.set_index('Lambda')\n",
    "lasso_bo_val.plot(logx = True, logy = True, ax = axes[2], legend = False)\n",
    "\n",
    "# Set y labels\n",
    "axes[0].set_ylabel('MSE')\n",
    "axes[1].set_ylabel('MSE')\n",
    "axes[2].set_ylabel('MSE')\n",
    "\n",
    "# Set titles\n",
    "axes[0].set_title('(A)  IMDb \\n average rating')\n",
    "axes[1].set_title('(B)  RT \\n Tomatometer')\n",
    "axes[2].set_title('(B)  Log worldwide \\n box office')\n",
    "\n",
    "# Adjust spacing\n",
    "plt.subplots_adjust(hspace = 0.6)\n",
    "plt.subplots_adjust(wspace = 0.65)\n",
    "\n",
    "# Creating common legend\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc = (0.455, 0.02))\n",
    "fig.subplots_adjust(bottom = 0.5)\n",
    "\n",
    "# Save figures\n",
    "plt.savefig('validation-curves.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make pipeline for Lasso\n",
    "pipe = make_pipeline(ElasticNet(random_state = 1))\n",
    "\n",
    "# Create lists for storing elastic nets\n",
    "gs_nets = []\n",
    "\n",
    "# Fit elastic nets for different targets, outputting MSE and R-squared for each\n",
    "for target in y_train: \n",
    "    gs_net = GridSearchCV(estimator = pipe, param_grid = {'elasticnet__alpha': np.logspace(-4, 4, 12), \\\n",
    "                      'elasticnet__l1_ratio': [0, 0.25, 0.5, 0.75, 1]}, \\\n",
    "                      scoring = 'neg_mean_squared_error', n_jobs = -1, iid = False, cv = 10, verbose = 0)\n",
    "    gs_net.fit(X_train, y_train[target])\n",
    "    \n",
    "    print(target + ':', mean_squared_error(y_test[target], gs_net.best_estimator_.predict(X_test)), r2_score(y_test[target], gs_net.best_estimator_.predict(X_test)))\n",
    "    \n",
    "    gs_nets.append(gs_net)\n",
    "    \n",
    "# Get coefficients regarding Reddit comments\n",
    "print(gs_nets[0].best_estimator_.steps[0][1].coef_[3:6])\n",
    "print(gs_nets[2].best_estimator_.steps[0][1].coef_[3:6])\n",
    "print(gs_nets[3].best_estimator_.steps[0][1].coef_[3:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipes\n",
    "lasso_pipe = make_pipeline(StandardScaler(), Lasso(random_state = 1))\n",
    "elastic_pipe = make_pipeline(ElasticNet(random_state = 1))\n",
    "\n",
    "# Create dataframes for Lasso with audience score\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = lasso_pipe, \\\n",
    "                   X = X_train,\n",
    "                   y = y_train['audienceScore'],\n",
    "                   train_sizes = np.arange(0.2, 1.05, .05),\n",
    "                   scoring = 'neg_mean_squared_error',                 \n",
    "                   cv = 10)    \n",
    "mse_lasso_audience = pd.DataFrame({'Validation': -test_scores.mean(axis = 1),\n",
    "                     'Train': -train_scores.mean(axis = 1)})\\\n",
    "                    .set_index(pd.Index(train_sizes, name = 'Sample size'))\n",
    "\n",
    "# Create dataframes for Lasso with Tomatometer\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = lasso_pipe, \\\n",
    "                   X = X_train,\n",
    "                   y = y_train['tomatoMeter'],\n",
    "                   train_sizes = np.arange(0.2, 1.05, .05),\n",
    "                   scoring = 'neg_mean_squared_error',                 \n",
    "                   cv = 10)\n",
    "mse_lasso_tomatom = pd.DataFrame({'Validation': -test_scores.mean(axis = 1),\n",
    "                     'Train': -train_scores.mean(axis = 1)})\\\n",
    "                    .set_index(pd.Index(train_sizes, name = 'Sample size'))\n",
    "\n",
    "# Create dataframes for Lasso with box office\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = lasso_pipe, \\\n",
    "                   X = X_train,\n",
    "                   y = y_train['boWorldwide'],\n",
    "                   train_sizes = np.arange(0.2, 1.05, .05),\n",
    "                   scoring = 'neg_mean_squared_error',                 \n",
    "                   cv = 10)\n",
    "mse_lasso_boworld = pd.DataFrame({'Validation': -test_scores.mean(axis = 1),\n",
    "                     'Train': -train_scores.mean(axis = 1)})\\\n",
    "                    .set_index(pd.Index(train_sizes, name = 'Sample size'))\n",
    "\n",
    "# Create dataframes for elastic net with audience score\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = elastic_pipe, \\\n",
    "                   X = X_train,\n",
    "                   y = y_train['audienceScore'],\n",
    "                   train_sizes = np.arange(0.2, 1.05, .05),\n",
    "                   scoring = 'neg_mean_squared_error',                 \n",
    "                   cv = 10)    \n",
    "mse_elastic_audience = pd.DataFrame({'Validation': -test_scores.mean(axis = 1),\n",
    "                     'Train': -train_scores.mean(axis = 1)})\\\n",
    "                    .set_index(pd.Index(train_sizes, name = 'Sample size'))\n",
    "\n",
    "# Create dataframes for elastic net with Tomatometer\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = elastic_pipe, \\\n",
    "                   X = X_train,\n",
    "                   y = y_train['tomatoMeter'],\n",
    "                   train_sizes = np.arange(0.2, 1.05, .05),\n",
    "                   scoring = 'neg_mean_squared_error',                 \n",
    "                   cv = 10)    \n",
    "mse_elastic_tomatom = pd.DataFrame({'Validation': -test_scores.mean(axis = 1),\n",
    "                     'Train': -train_scores.mean(axis = 1)})\\\n",
    "                    .set_index(pd.Index(train_sizes, name = 'Sample size'))\n",
    "\n",
    "# Create dataframes for elastic net with box office\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = elastic_pipe, \\\n",
    "                   X = X_train,\n",
    "                   y = y_train['boWorldwide'],\n",
    "                   train_sizes = np.arange(0.2, 1.05, .05),\n",
    "                   scoring = 'neg_mean_squared_error',                 \n",
    "                   cv = 10)    \n",
    "mse_elastic_boworld = pd.DataFrame({'Validation': -test_scores.mean(axis = 1),\n",
    "                     'Train': -train_scores.mean(axis = 1)})\\\n",
    "                    .set_index(pd.Index(train_sizes, name = 'Sample size'))\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(2, 3, figsize = (8, 4.5))\n",
    "\n",
    "# Create plots\n",
    "mse_lasso_audience.plot(ax = axes[0, 0], legend = False)\n",
    "mse_lasso_tomatom.plot(ax = axes[0, 1], legend = False)\n",
    "mse_lasso_boworld.plot(ax = axes[0, 2], legend = False)\n",
    "mse_elastic_audience.plot(ax = axes[1, 0], legend = False)\n",
    "mse_elastic_tomatom.plot(ax = axes[1, 1], legend = False)\n",
    "mse_elastic_boworld.plot(ax = axes[1, 2], legend = False)\n",
    "\n",
    "# Set titles\n",
    "axes[0, 0].set_title('(A)  Lasso with \\n audience score')\n",
    "axes[0, 1].set_title('(B)  Lasso with \\n Tomatometer')\n",
    "axes[0, 2].set_title('(C)  Lasso with \\n box office')\n",
    "axes[1, 0].set_title('(D)  Elastic net \\n with audience score')\n",
    "axes[1, 1].set_title('(E)  Elastic net \\n with Tomatometer')\n",
    "axes[1, 2].set_title('(F)  Elastic net \\n with box office')\n",
    "\n",
    "# Set y-labels\n",
    "axes[0, 0].set_ylabel('MSE')\n",
    "axes[0, 1].set_ylabel('MSE')\n",
    "axes[0, 2].set_ylabel('MSE')\n",
    "axes[1, 0].set_ylabel('MSE')\n",
    "axes[1, 1].set_ylabel('MSE')\n",
    "axes[1, 2].set_ylabel('MSE')\n",
    "\n",
    "# Adjust spacing\n",
    "plt.subplots_adjust(hspace = 1.1)\n",
    "plt.subplots_adjust(wspace = 0.5)\n",
    "\n",
    "# Create common label\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc = (0.475, 0.025))\n",
    "fig.subplots_adjust(bottom = 0.25)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('learning-curves.pdf', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
