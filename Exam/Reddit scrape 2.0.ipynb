{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from praw.models import MoreComments\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import nltk.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit API authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='BxrF2g9d3egQ4g', \\\n",
    "                     client_secret='T-pkCmWCBxLjVlNZk88OjvcH7sk', \\\n",
    "                     user_agent='SDS2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download comments for movies on reddit with timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_comments(movie_title, testing = True):\n",
    "    subreddit = reddit.subreddit('movies')\n",
    "    \n",
    "    comments = []\n",
    "    subid = []\n",
    "    treeid = []\n",
    "    date = []\n",
    "    \n",
    "    searchresults = subreddit.search(movie_title, sort = 'top')\n",
    "    i = 0\n",
    "    for subidx, submission in enumerate(searchresults):\n",
    "        \n",
    "        if testing:\n",
    "            if i > 5:\n",
    "                break\n",
    "            i += 1\n",
    "            \n",
    "        try:\n",
    "            comment_tree = submission.comments.list()\n",
    "            for treeidx, top_lvl_comment in enumerate(comment_tree):\n",
    "                \n",
    "                # Erstat disse to linjer hvis i vil have \n",
    "                # data ud af \"morecomments\" objekterne\n",
    "                if isinstance(top_lvl_comment, MoreComments):\n",
    "                    continue\n",
    "                \n",
    "                subid.append(subidx)\n",
    "                comments.append(top_lvl_comment.body)\n",
    "                treeid.append(treeidx)\n",
    "                date.append(top_lvl_comment.created_utc)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "    df = pd.DataFrame({'submission': subid, 'comment_tree': treeid, 'comment': comments, 'date': date})\n",
    "    df['date'] = pd.to_datetime(df['date'], unit = 's')\n",
    "    df = df.set_index(['date'])\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    #df_before = df[:release_date - datetime.timedelta(days = 1)]\n",
    "    #df_after = df[release_date:release_date + datetime.timedelta(days = 60)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TESTING STUFF #####\n",
    "#release_date = datetime.date(year = 2019, month = 7, day = 26)\n",
    "#df = get_reddit_comments('once upon a time in hollywood', release_date, testing = True)\n",
    "#print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TESTING STUFF #####\n",
    "#print(once_upon)\n",
    "#pd.options.display.max_colwidth = 3000\n",
    "#once_upon['comment'].iloc[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguistic analysis of commments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(movie_df):\n",
    "    vader = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n",
    "    vader_df = pd.DataFrame(list(movie_df['comment'].apply(vader.polarity_scores)))\n",
    "    vader_mean = vader_df['compound'].mean()\n",
    "    return vader_mean, len(vader_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing movies and release dates from movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('full.pkl')\n",
    "df = df[df['year'] >= 2013]\n",
    "\n",
    "movie_list = df['title'].tolist()\n",
    "date_list = df['releaseDate'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting sentiment scores for all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#movie_list = ['avengers endgame', 'captain marvel', 'hobbs & shaw']\n",
    "#date_list = [datetime.date(2019, 4, 26), datetime.date(2019, 3, 8), datetime.date(2019, 8, 2)]\n",
    "\n",
    "sentiments_before = []\n",
    "sentiments_after = []\n",
    "num_comments_before = []\n",
    "num_comments_after = []\n",
    "i = 1\n",
    "for movie, date in zip(movie_list, date_list):\n",
    "    try:\n",
    "        comments = get_reddit_comments(movie, testing = False)\n",
    "    except:\n",
    "        sentiments_before.append(None)\n",
    "        sentiments_after.append(None)\n",
    "        num_comments_before.append(None)\n",
    "        num_comments_after.append(None)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        comments_before = comments[:date - datetime.timedelta(days = 1)]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        comments_after = comments[date:date + datetime.timedelta(days = 60)]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        snt_before = sentiment(comments_before)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        snt_after = sentiment(comments_after)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        sentiments_before.append(snt_before[0])\n",
    "    except:\n",
    "        sentiments_before.append(None)\n",
    "        \n",
    "    try:\n",
    "        sentiments_after.append(snt_after[0])\n",
    "    except:\n",
    "        sentiments_after.append(None)\n",
    "        \n",
    "\n",
    "    try:\n",
    "        num_comments_before.append(snt_before[1])\n",
    "    except:\n",
    "        num_comments_before.append(None)\n",
    "        \n",
    "    try:\n",
    "        num_comments_after.append(snt_after[1])\n",
    "    except:\n",
    "        num_comments_after.append(None)\n",
    "        \n",
    "    print(i)\n",
    "    i += 1\n",
    "\n",
    "df['sentimentBefore'] = sentiments_before\n",
    "df['sentimentAfter'] = sentiments_after\n",
    "df['numCommentsBefore'] = num_comments_before\n",
    "df['numCommentsAfter'] = num_comments_after\n",
    "\n",
    "df.to_pickle('full_with_sentiment.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiments_before)\n",
    "print(sentiments_after)\n",
    "print(num_comments_before)\n",
    "print(num_comments_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
